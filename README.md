# ğŸ™ï¸ Analyze Voice Calls - ML Model with RL & Sentiment Feedback

A voice-based AI assistant that explains government schemes to farmers, listens to their replies, and **learns how to speak better** through reinforcement learning. This project combines **speech-to-text**, **sentiment analysis**, **text-to-speech**, and **reward-based learning** to simulate a real-world rural advisory assistant.

---

## ğŸ“Œ Key Features

| Feature | Description |
|--------|-------------|
| ğŸ§  Reinforcement Learning | Improves messaging using feedback from farmer responses |
| ğŸ—£ï¸ Text-to-Speech (TTS) | Talks to farmers using `pyttsx3` |
| ğŸ§ Speech-to-Text (STT) | Uses `OpenAI Whisper` to understand voice replies |
| ğŸ’¬ Sentiment Analysis | Judges tone of voice to reward/penalize the message |
| ğŸ“Š Learning Loop | Stores performance, adjusts future prompts |
| ğŸ’¾ Q-table Storage | Saves agent state using `pickle` for persistent learning |

---

## ğŸŒ¾ Real-World Use Case

> â€œImagine an AI calling a farmer and explaining a solar subsidy.  
> The farmer responds, unsure.  
> The AI understands the confusion â€” and next time, simplifies the message.â€  

This project is a **foundation for voice-based rural assistants** â€” ideal for agriculture, helplines, and public outreach.

---

## ğŸš€ Getting Started

### ğŸ§© Prerequisites

Make sure you have Python 3.8+ and install the following:

```bash
pip install -r requirements.txt
```
Or install manually:


``` bash
pip install openai-whisper pyttsx3 textblob torch torchaudio stable-baselines3
```
Note: Whisper may require FFmpeg and compatible CUDA drivers.

##ğŸ“‚ Folder Structure
```
â”œâ”€â”€ agent.py           # RL logic and Q-table
â”œâ”€â”€ speech.py          # Handles TTS and STT
â”œâ”€â”€ sentiment.py       # Analyzes farmer response tone
â”œâ”€â”€ main.py            # Main loop for training the agent
â”œâ”€â”€ utils/             # Helpers for saving/loading models
â”œâ”€â”€ recordings/        # (Optional) Voice logs or audio samples
â””â”€â”€ q_table.pkl        # Saved Q-table for learning history
```

## ğŸ§ª How It Works
The assistant chooses a message to deliver.

It speaks using TTS (pyttsx3).

Farmer response is recorded or simulated and passed through Whisper STT.

Sentiment is analyzed (positive/neutral/negative).

A reward is calculated and Q-table updated.

The loop continues â€” improving the assistant's strategy.


## ğŸ”„ Advanced Options
Enhancement	How to Activate
ğŸ§  True RL Agent	Use Stable-Baselines3 instead of Q-table
ğŸ§ Real Audio	Replace simulated replies with .wav recordings
ğŸ¤ Whisper STT	Use actual Whisper transcription for input
ğŸ“ˆ Metrics	Log accuracy, sentiment trends, engagement

## ğŸ› ï¸ Future Ideas
Replace synthetic voices with real farmer voice samples

Use GPT-4 to generate clearer messages dynamically

Integrate with IVR or Twilio for real-time call flow

Add translation for regional languages

## ğŸ‘¨â€ğŸ”¬ Authors
Zian Rajeshkumar Surani
@Zian-Surani | AI for Good | SRM IST Trichy

## ğŸ“œ License
This project is licensed under the MIT License.

## ğŸ’¡ Inspiration
Inspired by the vision of using AI for digital inclusion in agriculture, helping rural populations access schemes, services, and support through intelligent voice systems.

â€œTechnology should talk to people â€” not the other way around.â€
